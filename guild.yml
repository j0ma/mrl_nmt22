- config: basic-flags
  flags:
    experiment_name:
      type: string
      required: true
    seed:
      type: int
      default: 1917
    gpu_device:
      type: string
      default: 1
- config: transformer-flags
  flags:
    criterion:
      type: string
      default: "label_smoothed_cross_entropy"
    label_smoothing:
      type: float
      default: 0.1
    lr:
      type: float
      default: 0.0003
    lr_scheduler:
      type: string
      default: "fixed"
    warmup_init_lr:
      type: float
      default: 0.00000001
    clip_norm:
      type: float
      default: 1.0
    save_interval:
      type: int
      default: 5
    activation_fn:
      type: string
      default: "relu"
    encoder_layers:
      type: int
      default: 4
    decoder_layers:
      type: int
      default: 4
    encoder_attention_heads:
      type: int
      default: 8
    decoder_attention_heads:
      type: int
      default: 8
    decoder_embedding_dim:
      type: int
      default: 200
    decoder_hidden_size:
      type: int
      default: 1024
    encoder_embedding_dim:
      type: int
      default: 200
    encoder_hidden_size:
      type: int
      default: 1024
    batch_size:
      type: int
      default: 64
    optimizer:
      type: string
      default: "adadelta"
    p_dropout:
      type: float
      default: 0.2
    max_update:
      type: int
      default: 0
    max_epoch:
      type: int
      default: 5
    validate_interval:
      type: int
      default: 1
    validate_interval_updates:
      type: int
      default: 5000
    warmup_updates:
      type: int
      default: 10000

- operations:
    prep_experiment:
      description: "Prepares an experiment folder for an MT experiment"
      exec: "bash prep_experiment.sh ${experiment_name} ${raw_data_folder} ${bin_data_folder}"
      flags:
        $include: basic-flags
        raw_data_folder:
          type: string
          required: true
        bin_data_folder:
          type: string
          required: true
      requires:
        - file: data-bin
        - file: checkpoints
        - file: experiments
        - file: prep_experiment.sh
    train_transformer:
      description: "Train transformer model"
      exec: "bash scripts/train_transformer ${seed} ${criterion} ${label_smoothing} ${optimizer} ${lr} ${lr_scheduler} ${warmup_init_lr} ${warmup_updates} ${clip_norm} ${max_update} ${save_interval} ${encoder_layers} ${encoder_attention_heads} ${decoder_layers} ${decoder_attention_heads} ${activation_fn} ${batch_size} ${p_dropout} ${decoder_embedding_dim} ${decoder_hidden_size} ${encoder_embedding_dim} ${encoder_hidden_size} ${experiment_name} ${gpu_device} ${validate_interval} ${validate_interval_updates} ${src_lang} ${tgt_lang} ${max_epoch}"
      flags:
        $include:
          - basic-flags
          - transformer-flags
        src_lang:
            type: string
            required: true
        tgt_lang:
            type: string
            required: true
      requires:
        - file: data-bin
        - file: scripts
        - file: checkpoints
        - file: experiments
    evaluate_transformer:
      description: "Evaluate transformer model"
      exec: "bash scripts/evaluate_transformer ${experiment_name} ${mode} ${beam_size} ${seed} ${gpu_device} ${model_name} ${src_lang} ${tgt_lang} ${remove_preprocessing} ${casing}"
      flags:
        $include:
          - basic-flags
        model_name:
          type: string
          default: "transformer"
        mode:
          type: string
          default: "dev"
        beam_size:
          type: int
          default: 5
        src_lang:
            type: string
            required: true
        tgt_lang:
            type: string
            required: true
        remove_preprocessing:
            type: string
            default: "none"
        casing:
            type: string
            default: "none"
      output-scalars:
        - 'EVAL_SCALAR: (\key)\t(\value)'
      requires:
        - file: data-bin
        - file: scripts
        - file: checkpoints
        - file: experiments
    experiment_pipeline:
      description: "Prep experiment -> train model -> evaluate model"
      flags:
        $include:
          - basic-flags
          - transformer-flags
        mode:
          type: string
          default: "dev"
        beam_size:
          type: int
          default: 5
        suffix:
          default: ''
        src_lang:
            type: string
            required: true
        tgt_lang:
            type: string
            required: true
      steps:
        - run: prep_experiment
          flags:
            experiment_name: '${experiment_name}-lr${lr}-eed${encoder_embedding_dim}-ehs${encoder_hidden_size}-ded${decoder_embedding_dim}-dhs${decoder_hidden_size}-bs${batch_size}-dropout${p_dropout}-clip_norm${clip_norm}-gpu${gpu_device}'
        - run: train_loresmt_transformer
          flags:
            experiment_name: '${experiment_name}-lr${lr}-eed${encoder_embedding_dim}-ehs${encoder_hidden_size}-ded${decoder_embedding_dim}-dhs${decoder_hidden_size}-bs${batch_size}-dropout${p_dropout}-clip_norm${clip_norm}-gpu${gpu_device}'
            criterion: '${criterion}'
            label_smoothing: '${label_smoothing}'
            lr: '${lr}'
            lr_scheduler: '${lr_scheduler}'
            warmup_init_lr: '${warmup_init_lr}'
            clip_norm: '${clip_norm}'
            save_interval: '${save_interval}'
            activation_fn: '${activation_fn}'
            gpu_device: '${gpu_device}'
            encoder_layers: '${encoder_layers}'
            decoder_layers: '${decoder_layers}'
            encoder_attention_heads: '${encoder_attention_heads}'
            decoder_attention_heads: '${decoder_attention_heads}'
            decoder_hidden_size: '${decoder_hidden_size}'
            decoder_embedding_dim: '${decoder_embedding_dim}'
            encoder_hidden_size: '${encoder_hidden_size}'
            encoder_embedding_dim: '${encoder_embedding_dim}'
            batch_size: '${batch_size}'
            optimizer: '${optimizer}'
            p_dropout: '${p_dropout}'
            max_update: '${max_update}'
            validate_interval: '${validate_interval}'
            validate_interval_updates: '${validate_interval_updates}'
            warmup_updates: '${warmup_updates}'
        - run: evaluate_transformer
          flags:
            experiment_name: '${experiment_name}-lr${lr}-eed${encoder_embedding_dim}-ehs${encoder_hidden_size}-ded${decoder_embedding_dim}-dhs${decoder_hidden_size}-bs${batch_size}-dropout${p_dropout}-clip_norm${clip_norm}-gpu${gpu_device}'
            mode: '${mode}'
            beam_size: '${beam_size}'
            gpu_device: '${gpu_device}'
      requires:
        - file: data
        - file: data-bin
        - file: models
        - file: checkpoints
        - file: experiments
        - file: evaluate.py
      compare:
        - ler
        - wer
        - mean_f1
        - word_acc
        - bleu
