# Configs
- config: basic-flags
  flags:
    experiment_name:
      type: string
      required: true
    src_lang:
      type: string
      required: true
    tgt_lang:
      type: string
      required: true
    model_name:
      type: string
      default: "transformer"
    seed:
      type: int
      default: 1917
    gpu_device:
      type: string
      default: 1
- config: prep-flags
  flags:
    raw_data_folder:
      type: string
      required: true
    bin_data_folder:
      type: string
      required: true
- config: evaluate-flags
  flags:
    mode:
      type: string
      default: "dev"
    beam_size:
      type: int
      default: 5
    remove_preprocessing_source:
      type: string
      default: "none"
    remove_preprocessing_hypotheses:
      type: string
      default: "none"
    remove_preprocessing_reference:
      type: string
      default: "none"
    remove_preprocessing_reference_clean:
      type: string
      default: "none"
    detokenize_source:
      type: boolean
      default: true
    detokenize_hypotheses:
      type: boolean
      default: true
    detokenize_reference:
      type: boolean
      default: true
    detokenize_reference_clean:
      type: boolean
      default: false
- config: transformer-flags
  flags:
    criterion:
      type: string
      default: "label_smoothed_cross_entropy"
    label_smoothing:
      type: float
      default: 0.1
    lr:
      type: float
      default: 0.0003
    lr_scheduler:
      type: string
      default: "fixed"
    warmup_init_lr:
      type: float
      default: 0.00000001
    clip_norm:
      type: float
      default: 1.0
    save_interval_updates:
      type: int
      default: 25000
    activation_fn:
      type: string
      default: "relu"
    encoder_layers:
      type: int
      default: 4
    decoder_layers:
      type: int
      default: 4
    encoder_attention_heads:
      type: int
      default: 8
    decoder_attention_heads:
      type: int
      default: 8
    decoder_embedding_dim:
      type: int
      default: 200
    decoder_hidden_size:
      type: int
      default: 1024
    encoder_embedding_dim:
      type: int
      default: 200
    encoder_hidden_size:
      type: int
      default: 1024
    batch_size:
      type: int
      default: 64
    max_tokens:
      type: int
      default: 0
    optimizer:
      type: string
      default: "adadelta"
    p_dropout:
      type: float
      default: 0.2
    max_updates:
      type: int
      default: 0
    max_epoch:
      type: int
      default: 5
    validate_interval:
      type: int
      default: 1
    validate_interval_updates:
      type: int
      default: 5000
    warmup_updates:
      type: int
      default: 10000

# Data download ops
- model: data
  operations:
    download_til:
      description: "Download Turkic Interlingua corpus"
      main: scripts.download.download_til
      flags:
        download_folder:
          type: string
          required: true
        source_language:
          type: string
          required: true
        target_language:
          type: string
          required: true
        split:
          type: string
          required: true
          default: "all"
          choices:
            - train
            - dev
            - test
            - all

# Transformer ops
- model: nmt
  operations:
    prep_experiment:
      description: "Prepares an experiment folder for an MT experiment"
      exec: "bash scripts/prep_experiment.sh ${experiment_name} ${raw_data_folder} ${bin_data_folder} ${model_name}"
      flags:
        $include: ["basic-flags", "prep-flags"]
      requires:
        - file: data-bin
        - file: checkpoints
        - file: experiments
        - file: scripts
    train_transformer:
      description: "Train transformer model"
      exec: "bash scripts/train_transformer ${seed} ${criterion} ${label_smoothing} ${optimizer} ${lr} ${lr_scheduler} ${warmup_init_lr} ${warmup_updates} ${clip_norm} ${max_updates} ${save_interval_updates} ${encoder_layers} ${encoder_attention_heads} ${decoder_layers} ${decoder_attention_heads} ${activation_fn} ${batch_size} ${p_dropout} ${decoder_embedding_dim} ${decoder_hidden_size} ${encoder_embedding_dim} ${encoder_hidden_size} ${experiment_name} ${gpu_device} ${validate_interval} ${validate_interval_updates} ${src_lang} ${tgt_lang} ${max_epoch} ${model_name} ${max_tokens}"
      flags:
        $include: ["basic-flags", "transformer-flags"]
      requires:
        - file: data-bin
        - file: scripts
        - file: checkpoints
        - file: experiments
    evaluate_transformer:
      description: "Evaluate transformer model"
      exec: "bash scripts/evaluate_transformer ${experiment_name} ${mode} ${beam_size} ${seed} ${gpu_device} ${model_name} ${src_lang} ${tgt_lang} ${remove_preprocessing_source} ${remove_preprocessing_hypotheses} ${remove_preprocessing_references} ${remove_preprocessing_references_clean} ${detokenize_source} ${detokenize_hypotheses} ${detokenze_references} ${detokenize_references_clean}"
      flags:
        $include: ["basic-flags", "evaluate-flags"]
      output-scalars:
        - 'EVAL_SCALAR: (\key)\t(\value)'
      requires:
        - file: data-bin
        - file: scripts
        - file: checkpoints
        - file: experiments
    experiment_pipeline:
      description: "Prep experiment -> train model -> evaluate model"
      flags:
          $include: ["basic-flags", "prep-flags", "transformer-flags", "evaluate-flags"]
      steps:
          - run: prep_experiment
            flags:
                experiment_name: "${experiment_name}"
                src_lang: "${src_lang}"
                tgt_lang: "${tgt_lang}"
                model_name: "${model_name}"
                seed: "${seed}"
                gpu_device: "${gpu_device}"
                raw_data_folder: "${raw_data_folder}"
                bin_data_folder: "${bin_data_folder}"
          - run: train_transformer
            flags:
                experiment_name: "${experiment_name}"
                src_lang: "${src_lang}"
                tgt_lang: "${tgt_lang}"
                model_name: "${model_name}"
                seed: "${seed}"
                gpu_device: "${gpu_device}"
                criterion: "${criterion}"
                label_smoothing: "${label_smoothing}"
                lr: "${lr}"
                lr_scheduler: "${lr_scheduler}"
                warmup_init_lr: "${warmup_init_lr}"
                clip_norm: "${clip_norm}"
                save_interval_updates: "${save_interval_updates}"
                activation_fn: "${activation_fn}"
                encoder_layers: "${encoder_layers}"
                decoder_layers: "${decoder_layers}"
                encoder_attention_heads: "${encoder_attention_heads}"
                decoder_attention_heads: "${decoder_attention_heads}"
                decoder_embedding_dim: "${decoder_embedding_dim}"
                decoder_hidden_size: "${decoder_hidden_size}"
                encoder_embedding_dim: "${encoder_embedding_dim}"
                encoder_hidden_size: "${encoder_hidden_size}"
                batch_size: "${batch_size}"
                max_tokens: "${max_tokens}"
                optimizer: "${optimizer}"
                p_dropout: "${p_dropout}"
                max_updates: "${max_updates}"
                max_epoch: "${max_epoch}"
                validate_interval: "${validate_interval}"
                validate_interval_updates: "${validate_interval_updates}"
                warmup_updates: "${warmup_updates}"
          - run: evaluate_transformer
            flags:
                experiment_name: "${experiment_name}"
                src_lang: "${src_lang}"
                tgt_lang: "${tgt_lang}"
                model_name: "${model_name}"
                seed: "${seed}"
                gpu_device: "${gpu_device}"
                mode: "${mode}"
                beam_size: "${beam_size}"
                remove_preprocessing_source: "${remove_preprocessing_source}"
                remove_preprocessing_hypotheses: "${remove_preprocessing_hypotheses}"
                remove_preprocessing_references: "${remove_preprocessing_references}"
                remove_preprocessing_references_clean: "${remove_preprocessing_references_clean}"
                detokenize_source: "${detokenize_source}"
                detokenize_hypotheses: "${detokenize_hypotheses}"
                detokenize_references: "${detokenize_references}"
                detokenize_references_clean: "${detokenize_references_clean}"
      requires:
        - file: data-bin
        - file: scripts
        - file: checkpoints
        - file: experiments
